{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave \n",
    "import langid\n",
    "#import openai\n",
    "#import librosa\n",
    "\n",
    "import sklearn\n",
    "import pyaudio #python bindings for PortAudio the cross_platform audio i/o  library\n",
    "\n",
    "import fasttext\n",
    "import playsound\n",
    "from gtts import gTTS\n",
    "import librosa.display\n",
    "from langdetect import detect\n",
    "from pydub import AudioSegment\n",
    "import pyttsx3 #text to speech\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as sr #Speech to text\n",
    "from translate import Translator\n",
    "#from googletrans import Translator\n",
    "from tempfile import NamedTemporaryFile\n",
    "from IPython.display import Audio, display\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "#from transliterate import translit\n",
    "\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\\nbrew install ffmpeg\\nffmpeg -version\\n#pip install speechrecognition\\n#pip install pyttsx3\\n#pip install pyttsx4\\n#brew install portaudio\\n#pip uninstall pyaudio\\n#pip install pyaudio\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure pydub can find the ffmpeg/ffprobe binary\n",
    "AudioSegment.converter = \"ffmpeg\"  # path to ffmpeg binary\n",
    "\n",
    "#pip install translate\n",
    "#wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "'''/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "brew install ffmpeg\n",
    "ffmpeg -version\n",
    "#pip install speechrecognition\n",
    "#pip install pyttsx3\n",
    "#pip install pyttsx4\n",
    "#brew install portaudio\n",
    "#pip uninstall pyaudio\n",
    "#pip install pyaudio\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# choose_microphone\n",
    "def choose_microphone():\n",
    "    print(\"Available Microphones:\")\n",
    "    microphones = sr.Microphone.list_microphone_names()\n",
    "    for i, mic in enumerate(microphones):\n",
    "        print(f\"{i}: {mic}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter the index or name of the microphone you want to use to record audio: \")\n",
    "        if choice.isdigit():\n",
    "            choice = int(choice)\n",
    "            if 0 <= choice < len(microphones):\n",
    "                print(f\"The microphone used is {choice} : {microphones[choice]}.\")\n",
    "                return choice\n",
    "        elif choice in microphones:\n",
    "            print(f\"The microphone used is {choice} : {microphones[choice]}.\")\n",
    "            return choice\n",
    "        print(\"Invalid choice. Please enter a valid index or microphone name.\")\n",
    "\n",
    "\n",
    "# Function to translate \"I'm Listening to you...\" automatically\n",
    "def translit_message(text,language):\n",
    "    translator = Translator(to_lang=language)\n",
    "\n",
    "    try:\n",
    "        # Translate using translate library\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return f\"Language not supported for translation: {str(e)}\"\n",
    "\n",
    "\n",
    "# save input audio wave\n",
    "def save_input_audio(audio, c, save_dir=\"audio_in_out/inputs_audio\"):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Write wave file\n",
    "    sample_rate = 48000.0  # Hertz\n",
    "    frames = audio.get_wav_data()\n",
    "    wav_filename = os.path.join(save_dir, f\"input_audio_{c}.wav\")\n",
    "    with wave.open(wav_filename, 'w') as obj:\n",
    "        obj.setnchannels(1)  # Mono or 2\n",
    "        obj.setsampwidth(2)\n",
    "        obj.setframerate(sample_rate)\n",
    "        obj.writeframes(frames)\n",
    "    \n",
    "    print(f\"Audio has been saved to: {wav_filename}\")\n",
    "    return wav_filename\n",
    "\n",
    "\n",
    "# save output audio wave\n",
    "def save_output_audio(audio, c, save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Write wave file\n",
    "    sample_rate = 48000.0  # Hertz\n",
    "    frames = audio.get_wav_data()\n",
    "    wav_filename = os.path.join(save_dir, f\"output_audio_{c}.wav\")\n",
    "    with wave.open(wav_filename, 'w') as obj:\n",
    "        obj.setnchannels(1)  # Mono or 2\n",
    "        obj.setsampwidth(2)\n",
    "        obj.setframerate(sample_rate)\n",
    "        obj.writeframes(frames)\n",
    "    \n",
    "    print(f\"Audio has been saved to: {wav_filename}\")\n",
    "    return wav_filename\n",
    "\n",
    "\n",
    "# save the INPUT text output in a file \n",
    "def input_text_to_file(text, c, save_dir=\"text_in_out/inputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"input_text_{c}.txt\")\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(text + \"\\n\")\n",
    "        print(text,\" was written in \",file_path)\n",
    "\n",
    "\n",
    "# save the OUTPUT text output in a file \n",
    "def output_text_to_file(text, c, save_dir=\"text_in_out/outputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"output_text_{c}.txt\")\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(text + \"\\n\")\n",
    "        print(text,\" was written in \",file_path)\n",
    "\n",
    "\n",
    "# record Speech and convert it to Text as input\n",
    "def record_speech_to_text(chosen_microphone,c,language):\n",
    "    recognizer = sr.Recognizer()\n",
    "    #get audio and save it\n",
    "    with sr.Microphone(device_index=chosen_microphone) as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Adjust for noise\n",
    "        translation=translit_message(\"Hello I'm listening, how can I help you?\",language)\n",
    "        text_to_speech(translation, language) \n",
    "        print(translation,\"...\")\n",
    "        '''if language=='en' :\n",
    "            print(\"Listening...\")\n",
    "        elif language=='ar':\n",
    "            print(\"...في الاستماع\")\n",
    "        elif language=='fr':\n",
    "            print(\"écoute...\")'''\n",
    "        audio = recognizer.listen(source)\n",
    "        # Save the captured audio to a WAV file\n",
    "        wav_filename = save_input_audio(audio, c)\n",
    "\n",
    "        # Play back the captured audio\n",
    "        #play_audio(audio)\n",
    "        playsound.playsound(wav_filename)  # Play the input wav file in recorded voice instead of speak it \n",
    "\n",
    "    #convert audio to text\n",
    "    try:\n",
    "        # Use Google's speech recognition with language detection\n",
    "        text = recognizer.recognize_google(audio, language=language) # Use Google's speech recognition and Specify language parameter for Arabic ('ar')\n",
    "        print(\"audio has been converted to : \",text)\n",
    "        #input_text_to_file(text, c)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format(e))\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# read the INPUT text from a file\n",
    "def read_text_from_inputs(c,save_dir=\"text_in_out/inputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"input_text_{c}.txt\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# read the OUTPUT text from a file\n",
    "def read_text_from_outputs(c,save_dir=\"text_in_out/outputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"output_text_{c}.txt\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# speak the text_output and save it in a file \n",
    "def text_to_speech(text, lang):\n",
    "    if not text:\n",
    "        translation = translit_message(\"There is no text_to_speech conversion.\", lang)\n",
    "        print(translation)\n",
    "        return  # Return if there is no text to convert\n",
    "\n",
    "    # Convert text to speech\n",
    "    with NamedTemporaryFile(delete=False) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "        tmp_mp3.flush()  # Ensure all data is written to the file\n",
    "\n",
    "        # Play the speech\n",
    "        playsound.playsound(tmp_mp3.name, True)\n",
    "\n",
    "\n",
    "\n",
    "# speak the text_output and save it in a file \n",
    "def text_to_speach_input(text, lang, c, audio_save_dir=\"audio_in_out/inputs_audio\"):\n",
    "    if not text:\n",
    "        translation=translit_message(\"There is no text_to_speech conversion.\",lang)\n",
    "        print(translation)\n",
    "        return\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")\n",
    "        '''\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "        \n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"input_audio_{c}.wav\")\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "# speak the text_output and save it in a file \n",
    "def text_to_speach_output(text, lang, c, audio_save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    if not text:\n",
    "        translation=translit_message(\"There is no text_to_speech conversion.\",lang)\n",
    "        print(translation)\n",
    "        return\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")\n",
    "        '''\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "        \n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"output_audio_{c}.wav\")\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "# speak the text_output from a file and save it in an audio \n",
    "def text_to_speach_output_from_file(c, audio_save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"output_audio_{c}.wav\")\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "\n",
    "    # Read the text from the file\n",
    "    text = read_text_from_outputs(c)\n",
    "    if not text:\n",
    "        #translation=translit_message(\"There is no text_to_speech conversion.\",language_code)\n",
    "        #print(translation)\n",
    "        print(\"There is no text_to_speech conversion.\")\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")'''\n",
    "        return\n",
    "    language_code, language = detect_language(text)\n",
    "    print(\"text: \", text, \" in \",language)\n",
    "\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text,lang=language_code)#, \n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to detect the language of the input text\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')# Pre-Trained model for language identification\n",
    "# Language code to language name mapping\n",
    "language_mapping = {\n",
    "    \"af\": \"Afrikaans\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"de\": \"German\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"et\": \"Estonian\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"ka\": \"Georgian\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"lt\": \"Lithuanian\",\n",
    "    \"lv\": \"Latvian\",\n",
    "    \"mk\": \"Macedonian\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"mr\": \"Marathi\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sk\": \"Slovak\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sq\": \"Albanian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"tl\": \"Tagalog\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    # Add more languages as needed\n",
    "}\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    # Remove newline characters from the input text\n",
    "    text = text.replace('\\n', ' ')\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    language_name = language_mapping.get(language_code, \"Unknown\")\n",
    "    return language_code, language_name\n",
    "\n",
    "#'''\n",
    "#play audio function\n",
    "def play_audio(audio):\n",
    "    audio_data = audio.get_wav_data()\n",
    "    with wave.open(\"temp_audio.wav\", \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "        f.setframerate(16000)\n",
    "        f.writeframes(audio_data)\n",
    "        \n",
    "    # Open the temporary WAV file and play it\n",
    "    p = pyaudio.PyAudio()\n",
    "    wf = wave.open(\"temp_audio.wav\", \"rb\")# read byte mode\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(1024)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(1024)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Microphones:\n",
      "0: Built-in Microphone\n",
      "1: Built-in Output\n",
      "2: USB Audio Device\n",
      "3: USB Audio Device\n",
      "4: Soundflower (2ch)\n",
      "5: Soundflower (64ch)\n",
      "6: Screenflick Loopback\n",
      "7: iShowU Audio Capture\n",
      "8: Périphérique agrégé\n",
      "9: Périphérique à sortie multiple\n",
      "The microphone used is 3 : USB Audio Device.\n"
     ]
    }
   ],
   "source": [
    "# choose_microphone\n",
    "chosen_microphone = choose_microphone()#3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test audio:\n",
    "#text_to_speech(\"Hello, how are you?\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "كيف حالك أنا أستمع إليك... ؟\n",
      "how are you I'm Listening to you...?\n",
      "comment tu fais je t'écoute... ?\n",
      "come ti sto ascoltando...?\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Function to translate \"I'm Listening to you...\" automatically\n",
    "text=\"how are you I'm Listening to you...?\"\n",
    "print(translit_message(text,'ar'))  # Output: أنا أستمع إليك... (or similar in Arabic)\n",
    "print(translit_message(text,'en'))  # Output: I'm Listening to you...\n",
    "print(translit_message(text,'fr'))  # Output: Je vous écoute... (or similar in French)\n",
    "print(translit_message(text,'it'))  # Output: 我在听你... (or similar in Chinese)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# save the INPUT text output in a file \\ninput_text_to_file(\"كم الساعة الان؟\", 1)\\n\\n\\n# save the OUTPUT text output in a file \\noutput_text_to_file(\"الساعة الان الواحدة و النصف \",1)#'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# save the INPUT text output in a file \n",
    "input_text_to_file(\"كم الساعة الان؟\", 1)\n",
    "\n",
    "\n",
    "# save the OUTPUT text output in a file \n",
    "output_text_to_file(\"الساعة الان الواحدة و النصف \",1)#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبًا، أنا أستمع، كيف يمكنني مساعدتك ؟ ...\n",
      "Audio has been saved to: audio_in_out/inputs_audio/input_audio_6.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# record Speech and convert it to Text as input\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_speech_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_microphone\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext recorded: \u001b[39m\u001b[38;5;124m\"\u001b[39m,text)\u001b[38;5;66;03m#'''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 108\u001b[0m, in \u001b[0;36mrecord_speech_to_text\u001b[0;34m(chosen_microphone, c, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     wav_filename \u001b[38;5;241m=\u001b[39m save_input_audio(audio, c)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Play back the captured audio\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mplay_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#convert audio to text\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Use Google's speech recognition with language detection\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 358\u001b[0m, in \u001b[0;36mplay_audio\u001b[0;34m(audio)\u001b[0m\n\u001b[1;32m    356\u001b[0m data \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mreadframes(\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m data:\n\u001b[0;32m--> 358\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     data \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mreadframes(\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m    360\u001b[0m stream\u001b[38;5;241m.\u001b[39mstop_stream()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyaudio/__init__.py:550\u001b[0m, in \u001b[0;36mPyAudio.Stream.write\u001b[0;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[1;32m    547\u001b[0m     width \u001b[38;5;241m=\u001b[39m get_sample_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format)\n\u001b[1;32m    548\u001b[0m     num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels \u001b[38;5;241m*\u001b[39m width))\n\u001b[0;32m--> 550\u001b[0m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexception_on_underflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# record Speech and convert it to Text as input\n",
    "text = record_speech_to_text(chosen_microphone,6,'ar')\n",
    "print(\"text recorded: \",text)#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  كم عدد ايام الاسبوع\n",
      "\n",
      "\n",
      "The response audio has been saved to: audio_in_out/outputs_audio/output_audio_13.wav\n"
     ]
    }
   ],
   "source": [
    "'''# read the INPUT text from a file\n",
    "input=read_text_from_inputs(0)\n",
    "print(\"input: \",input)\n",
    "\n",
    "# read the OUTPUT text from a file\n",
    "output=read_text_from_outputs(13)\n",
    "print(\"output: \",output)\n",
    "\n",
    "#language_code, language = detect_language(output) #get language of output\n",
    "#text_to_speach_output(output, language_code, c) # speak the text_output and save it in a file '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Example usage\\nprompt1 = \"Cómo estás hoy\"\\nprompt2 = \"Bonjour Speechy\"\\nprompt3 = \"Hello Speechy how are you\"\\nprompt4 = \"مرحبا سبيشي\"\\n\\ncode1, name1 = detect_language(prompt1)\\ncode2, name2 = detect_language(prompt2)\\ncode3, name3 = detect_language(prompt3)\\ncode4, name4 = detect_language(prompt4)\\n\\nprint(f\"The detected language1 is: {code1} ({name1})\")\\nprint(f\"The detected language2 is: {code2} ({name2})\")\\nprint(f\"The detected language3 is: {code3} ({name3})\")\\nprint(f\"The detected language4 is: {code4} ({name4})\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''detected language\n",
    "prompt1 = \"Cómo estás hoy\"\n",
    "prompt2 = \"Bonjour Speechy\"\n",
    "prompt3 = \"Hello Speechy how are you\"\n",
    "prompt4 = \"مرحبا سبيشي\"\n",
    "\n",
    "code1, name1 = detect_language(prompt1)\n",
    "code2, name2 = detect_language(prompt2)\n",
    "code3, name3 = detect_language(prompt3)\n",
    "code4, name4 = detect_language(prompt4)\n",
    "\n",
    "print(f\"The detected language1 is: {code1} ({name1})\")\n",
    "print(f\"The detected language2 is: {code2} ({name2})\")\n",
    "print(f\"The detected language3 is: {code3} ({name3})\")\n",
    "print(f\"The detected language4 is: {code4} ({name4})\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبًا، أنا أستمع، كيف يمكنني مساعدتك ؟ ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#GET INPUT\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_speech_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_microphone\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# record Speech and convert it to Text as input\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext recorded: \u001b[39m\u001b[38;5;124m\"\u001b[39m,input_text)\n\u001b[1;32m      7\u001b[0m input_text_to_file(input_text, c) \u001b[38;5;66;03m#save input to file in inputs_folder \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 103\u001b[0m, in \u001b[0;36mrecord_speech_to_text\u001b[0;34m(chosen_microphone, c, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(translation,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''if language=='en' :\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    print(\"Listening...\")\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03melif language=='ar':\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    print(\"...في الاستماع\")\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03melif language=='fr':\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    print(\"écoute...\")'''\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Save the captured audio to a WAV file\u001b[39;00m\n\u001b[1;32m    105\u001b[0m wav_filename \u001b[38;5;241m=\u001b[39m save_input_audio(audio, c)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/speech_recognition/__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/speech_recognition/__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# General Test\n",
    "c+=1\n",
    "\n",
    "#GET INPUT\n",
    "input_text = record_speech_to_text(chosen_microphone,c,'ar')# record Speech and convert it to Text as input\n",
    "print(\"text recorded: \",input_text)\n",
    "input_text_to_file(input_text, c) #save input to file in inputs_folder \n",
    "language_code, language = detect_language(input_text)\n",
    "print(\"input: \", input_text, \" in \",language)\n",
    "playsound.playsound(f\"audio_in_out/inputs_audio/input_audio_{c}.wav\")  # Play the input wav file in recorded voice instead of speak it \n",
    "#text_to_speach_input(input_text, language_code, c)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#GENERATE OUTPUT\n",
    "gen_output=read_text_from_inputs(c) #geting text from inputs insted of generating a new output based on the input    #(in futer) generating a new output based on the input   \n",
    "output_text_to_file(gen_output, c)  #save gen_output to a file in outputs_folder \n",
    "\n",
    "\n",
    "\n",
    "#GIVE OUTPUT\n",
    "#output=read_text_from_outputs(c)    #get output from outputs_folder\n",
    "#language_code, language = detect_language(output) #get language of output\n",
    "#text_to_speach_output(output, language_code, c) # speak the text_output and save it in a file \n",
    "text_to_speach_output_from_file(c)# speak the text_output from a file and save it in an audio '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(data, sr=sr)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram\n",
    "'''X = librosa.stft(data) #short-time Fourier transform (STFT)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Analysis, Spectral Centroid\n",
    "'''import sklearn.preprocessing\n",
    "\n",
    "\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=data, sr=sr)[0]\n",
    "print(spectral_centroids.shape)\n",
    "\n",
    "#computing the time variable for visualization\n",
    "plt.figure(figsize=(14,5))\n",
    "frames = range(len(spectral_centroids))\n",
    "t= librosa.frames_to_time(frames)\n",
    "\n",
    "#normalizing the spectral centroids for visualisation\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=0)\n",
    "#plotting the spectral centroids along the waveform\n",
    "librosa.display.waveshow(data, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='b')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import speech_recognition as sr\n",
    "\n",
    "def list_microphones():\n",
    "    for i, mic in enumerate(sr.Microphone.list_microphone_names()):\n",
    "        print(f\"{i}: {mic}\")\n",
    "\n",
    "def choose_microphone():\n",
    "    print(\"Please choose a microphone from the list:\")\n",
    "    list_microphones()\n",
    "    mic_index = int(input(\"Enter the microphone index: \"))\n",
    "    return mic_index\n",
    "\n",
    "def record_text(mic_index, recognizer):\n",
    "    with sr.Microphone(device_index=mic_index) as source:\n",
    "        print(\"Say something!\")\n",
    "        audio = recognizer.listen(source)\n",
    "    return audio\n",
    "\n",
    "def main():\n",
    "    recognizer = sr.Recognizer()\n",
    "    chosen_microphone = choose_microphone()\n",
    "\n",
    "    try:\n",
    "        audio = record_text(chosen_microphone, recognizer)\n",
    "        text = recognizer.recognize_google(audio, language='ar')\n",
    "        print(\"You said: \" + text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect Language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect the language of the input text\n",
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')# Pre-Trained model for language identification\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''prompt1 = \"Cómo estás hoy\"\n",
    "prompt2 = \"Bonjour Speechy\"\n",
    "prompt3 = \"Hello Speechy how are you\"\n",
    "prompt4 = \"مرحبا سبيشي\"\n",
    "\n",
    "print(f\"The detected language1 is: {detect_language(prompt1)}\")\n",
    "print(f\"The detected language2 is: {detect_language(prompt2)}\")\n",
    "print(f\"The detected language3 is: {detect_language(prompt3)}\")\n",
    "print(f\"The detected language4 is: {detect_language(prompt4)}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Record audio\n",
    "audio_file = \"recorded_audio.wav\"\n",
    "record_audio(audio_file)\n",
    "\n",
    "# Convert the recorded audio to text\n",
    "text = speech_to_text(audio_file)\n",
    "if text:\n",
    "    print(f\"Transcribed Text: {text}\")\n",
    "    # Detect the language of the transcribed text\n",
    "    language = detect_language(text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "else:\n",
    "    print(\"Could not transcribe the audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have a function `generate_response` that uses GPT-4\n",
    "'''# Function to generate a response using a multilingual model\n",
    "'' 'def generate_response(prompt, language):\n",
    "    # For simplicity, assume we're using a multilingual variant of GPT-4 or similar\n",
    "    # Load a pre-trained model and tokenizer\n",
    "    model_name = 'gpt-4-multilingual'\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    print(tokenizer)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # Encode the input prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=100, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response'' '\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate a response using a multilingual translation model\n",
    "def generate_response(prompt, language):\n",
    "    # Load the pre-trained model and tokenizer for translation\n",
    "    model_name = 'Helsinki-NLP/opus-mt-mul-en'\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    print(tokenizer)\n",
    "\n",
    "    ' ''model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    # Translate prompt to English for processing\n",
    "    translated = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    translated_text = model.generate(translated)\n",
    "    translated_prompt = tokenizer.decode(translated_text[0], skip_special_tokens=True)\n",
    "\n",
    "    # Here you would use a GPT model to generate a response in English\n",
    "    # For simplicity, let's mock this step with a simple response\n",
    "    response_in_english = f\"This is a generated response for: {translated_prompt}\"\n",
    "\n",
    "    # Translate the response back to the original language\n",
    "    back_translated = tokenizer.encode(response_in_english, return_tensors='pt')\n",
    "    back_translated_text = model.generate(back_translated)\n",
    "    final_response = tokenizer.decode(back_translated_text[0], skip_special_tokens=True)\n",
    "    \n",
    "    return final_response'' '\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"hello Speechy\"\n",
    "language = detect_language(prompt)\n",
    "print(f\"hello Speechy is in {language}\")\n",
    "\n",
    "generate_response(prompt, language)\n",
    "#response = generate_response(prompt, language)\n",
    "#print(response)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. googletrans  Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''translator = Translator()\n",
    "\n",
    "# Translate prompt to English\n",
    "translated_prompt = translator.translate(prompt, src=language, dest='en').text\n",
    "\n",
    "# Generate response in English\n",
    "response_in_english = generate_response(translated_prompt)\n",
    "\n",
    "# Translate response back to the detected language\n",
    "final_response = translator.translate(response_in_english, src='en', dest=language).text\n",
    "print(final_response)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import openai\n",
    "import langid\n",
    "from translate import Translator\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to detect the language of the input text using langid\n",
    "def detect_language(text):\n",
    "    lang, _ = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "# Function to translate text using the translate library\n",
    "def translate_text(text, from_lang, to_lang):\n",
    "    translator = Translator(from_lang=from_lang, to_lang=to_lang)\n",
    "    return translator.translate(text)\n",
    "\n",
    "# Function to generate a response using OpenAI's GPT-3/4\n",
    "def generate_response(prompt, language):\n",
    "    # Translate the prompt to English if it's not in English\n",
    "    if language != 'en':\n",
    "        prompt_in_english = translate_text(prompt, language, 'en')\n",
    "    else:\n",
    "        prompt_in_english = prompt\n",
    "    \n",
    "    # Generate a response using OpenAI's GPT-3/4\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt_in_english,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    response_in_english = response.choices[0].text.strip()\n",
    "    \n",
    "    # Translate the response back to the original language if it's not in English\n",
    "    if language != 'en':\n",
    "        final_response = translate_text(response_in_english, 'en', language)\n",
    "    else:\n",
    "        final_response = response_in_english\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# Example usage\n",
    "prompts = [\"Cómo estás hoy\", \"bonjour Speechy\", \"Hello Speechy how are you\", \"مرحبا سبيشي\"]\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    language = detect_language(prompt)\n",
    "    print(f\"Detected language for prompt {i}: {language}\")\n",
    "    response = generate_response(prompt, language)\n",
    "    print(f\"Response {i}: {response}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INPUT\n",
    "#select a microphone #chosen_microphone = choose_microphone()\n",
    "#get_input_audio 1\n",
    "#audio_to_text_input 1\n",
    "#save_text_to_file 1\n",
    "\n",
    "#### OUTPUT\n",
    "#generate_output_text 0\n",
    "#save_text_to_file 1\n",
    "#text_to_speech_autput 1\n",
    "#play_output 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play audio function\n",
    "def play_audio(audio):\n",
    "    audio_data = audio.get_wav_data()\n",
    "    with wave.open(\"temp_audio.wav\", \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "        f.setframerate(16000)\n",
    "        f.writeframes(audio_data)\n",
    "        \n",
    "    # Open the temporary WAV file and play it\n",
    "    p = pyaudio.PyAudio()\n",
    "    wf = wave.open(\"temp_audio.wav\", \"rb\")# read byte mode\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(1024)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(1024)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n",
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Record audio\n",
    "audio_file = \"/recorded_audio.wav\"\n",
    "record_audio(audio_file)\n",
    "\n",
    "'''# Convert the recorded audio to text\n",
    "text = speech_to_text(audio_file)\n",
    "if text:\n",
    "    print(f\"Transcribed Text: {text}\")\n",
    "    # Detect the language of the transcribed text\n",
    "    language = detect_language(text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "else:\n",
    "    print(\"Could not transcribe the audio.\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fasttext\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n",
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Function to save text to a file\n",
    "def save_text_to_file(text, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Function to read text from a specific paragraph in a file\n",
    "def read_paragraph_from_file(filename, paragraph_num):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        paragraphs = f.read().split(\"\\n\\n\")\n",
    "        if paragraph_num < len(paragraphs):\n",
    "            return paragraphs[paragraph_num]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "# Function to convert text to speech and save it as a wav file\n",
    "def text_to_speech(text, lang, output_file):\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(output_file, format=\"wav\")\n",
    "\n",
    "# Function to play the audio file\n",
    "def play_audio(file):\n",
    "    playsound(file)\n",
    "\n",
    "# Main process\n",
    "def main():\n",
    "    input_audio_file = \"input_audio.wav\"\n",
    "    transcribed_text_file = \"transcribed_text.txt\"\n",
    "    output_text_file = \"output_text.txt\"\n",
    "    output_audio_file = \"output_audio.wav\"\n",
    "\n",
    "    # INPUT\n",
    "    # Record audio\n",
    "    record_audio(input_audio_file)\n",
    "\n",
    "    # Convert audio to text\n",
    "    transcribed_text = speech_to_text(input_audio_file)\n",
    "    print(f\"Transcribed Text: {transcribed_text}\")\n",
    "\n",
    "    # Save transcribed text to a file\n",
    "    save_text_to_file(transcribed_text, transcribed_text_file)\n",
    "\n",
    "    # OUTPUT\n",
    "    # Generate output text (for simplicity, we will use the same transcribed text)\n",
    "    output_text = transcribed_text\n",
    "\n",
    "    # Save output text to a file\n",
    "    save_text_to_file(output_text, output_text_file)\n",
    "\n",
    "    # Detect language of the output text\n",
    "    language = detect_language(output_text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "\n",
    "    # Convert text to speech and save it as a wav file\n",
    "    text_to_speech(output_text, language, output_audio_file)\n",
    "\n",
    "    # Play the output audio\n",
    "    play_audio(output_audio_file)\n",
    "    print(f\"The response audio has been saved to: {output_audio_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
